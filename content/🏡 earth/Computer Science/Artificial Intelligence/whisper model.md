#concept

whisper is trained on `___` hours of audio data >> 680k
### References
1. https://github.com/openai/whisper/blob/main/model-card.md

### Notes
#todo 

- [ ] skim
	- [ ] colab https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb
		- [ ] know step by step how it works. 
	- [ ] model card https://github.com/openai/whisper/blob/main/model-card.md
- [ ] 1-pager explaining
- [ ] brainstorm a proposal why it's relevant to Viva
	- [ ] https://web.stanford.edu/class/cs224n/project/project-proposal-instructions-2022.pdf
- [ ] https://github.com/openai/whisper/blob/main/model-card.md

---


- how does a vanilla transformer LLM (2017) work?
	- is a transformer an encoder and decoder?
- How was the 680k audio data scraped?


Vanilla transformer 2017

[About whisper](https://twitter.com/karpathy/status/1573019733707788288?s=46&t=PrLWmbH5vc4JSFAi5f6ccg)

![[how whisper works.png]]