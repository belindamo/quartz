#concept 

activation function
[[SR/memory/f6B3GgyE.md|?]]
calculates an output based on input(s)
Used as a last step of neural network to normalize the output 
source: https://en.wikipedia.org/wiki/Activation_function
Activation functions include
- 1 fold x from previous layers
	- [[ReLu]]
	- [[tan h]]
- for a node
	- [[softmax function]]



