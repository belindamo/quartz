#concept

`softmax` >> an activation function that converts a vector of `K` real numbers into a probability distribution of `K` possible outcomes. 

use of `softmax` in a neural network >> It is often used as the last activation function of a neural network to normalize output of a network to a probability distribution over predicted output classes.


standard (unit) `softmax` equation
Hint:
- sigma is the output. a vector of real numbers that is normalized between 0 and 1
- z is input vector
- K is vector length
?
$$
\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^K e^{_j}}
$$

### References
1. 

### Notes




