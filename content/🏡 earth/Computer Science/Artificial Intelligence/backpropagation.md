#concept

backpropagation >> the process of doing forward and backward passes repeatedly on a model in order to minimize the error, until you reach the stopping criteria.<!--SR:!2024-09-28,6,250-->

### References
1. [[Build micrograd, a scalar-based neural network with Karpathy]]

### Notes
Note that it seems like definitions of backpropagation range from multiple forward+backward passes, to only updating gradients within backward pass, to backward pass. Doesn't seem like there is clear consensus.



