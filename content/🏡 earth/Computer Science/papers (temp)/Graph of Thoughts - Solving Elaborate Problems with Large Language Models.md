#paper #concept-pamphlet 
[[Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf]]
%% TODO-rr: read moreeeee %%
# Notes

In **Graph of Thoughts - Solving Elaborate Problems with Large Language Models**, Graph of Thoughts is a framework that does this >> a framework that advances prompting capabilities in LLMs beyond CoT/ToT, by modeling LLM-generated info as an *arbitrary graph*, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. 
<!--LEARN:Ojmvfm4w-->

## Key terms

- arbitrary graph

Graph of thought contains
- refining: self-reference
- backtracking: going back to prev node(s)
- aggregate chain


## Main contributions

![[Screenshot 2024-11-12 at 1.00.52 PM.png]]

system architecture
![[Screenshot 2024-11-12 at 1.01.58 PM.png]]
## Strengths and Weaknesses of paper
- Strengths
- Weaknesses

## Questions & Discussion Items
