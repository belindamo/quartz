---
date: 2024-02-20
---
## Summary

Operating System where the set of LLMs is like the CPU, that self-builds this library based on relevant multimodal contexts. 
(1) self-discovery of a multi-level library of symbolic checks and prompt-based reasoning
(2) long-context retrieval from library of function components
(3) caches of vectors for retrieving derived content
(4) database of exact-match multimodal user content
(5) Self-generated evals

## Related Works
Here are the clusters of research papers that have inspired this  
project:  
- Growing, interpretable knowledge base  
	- Dreamcoder (2020)  
	- Simulation Intelligence (2022)  
- Reasoning improvements via prompting and black-box  
	- Self-Discover (2024)  
	- GPT-4 with Wolfram Alpha on math problems (2023) 
- Relevant Open Source Language Models  
	- Llemma (2023)  
	- Llama (2023)  
	- lean-gptf (2021)  
- Automated theorem-provers  
	- Draft, Sketch, Prove (2023)  
	- LeanDojo: Theorem Proving with Retrieval-Augmented Language Models (2023)  
	- Auto-formalization of Large Language Models (2022)  
	- Generative Language Modeling for Automated Theorem Proving (2020)  
- Mathematics benchmarks and datasets  
	- LeanDojo (2023)  
	- MiniF2F (2022)  
	- MATH (2021)  

---

### Misc.

child::[[Back-translation for Alignment of LLM Generation of Code, Tests, and more]]